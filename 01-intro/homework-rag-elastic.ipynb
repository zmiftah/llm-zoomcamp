{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bc470c-dedc-4094-afc9-f3dbc9102245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/refs/heads/main/minsearch/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6434ea2-0213-4301-9268-4b84d2b08268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01e3d1c-4e55-44d2-af30-2bd33652daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a1bd3b-0e1b-40c3-ba5a-4b6456696557",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cfc816-858e-4625-aec7-ff6cdfe5f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f07126c-1068-49fc-97c2-bc1f47ba7708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b6656e-4251-4b87-9f02-87f8b86a005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f1cc01-8f3f-4e5a-9b55-16264bb32185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x79932c8bec00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cfd91a-7bde-4829-a26c-bc83f0c3f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0e7519-3797-432e-b0f1-2a89d562c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question':2.5, 'section':0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query, \n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost, \n",
    "        num_results=10\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "365593a2-77f5-4db6-bf1c-4adde11f397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "        \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51344b48-2883-4aa9-b155-823d63b3ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\"role\":\"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df0d0004-53fd-4a1b-ba6d-7f0fac467845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99540650-1a25-4672-8513-31d60f96910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To run Kafka, especially when dealing with a Python setup, it is recommended to create a virtual environment and manage dependencies within that environment. Here's how you can do it:\\n\\n1. **Create a Virtual Environment:**\\n   - Run this command to create a virtual environment:\\n     ```\\n     python -m venv env\\n     ```\\n   - Activate the environment:\\n     - On MacOS or Linux:\\n       ```\\n       source env/bin/activate\\n       ```\\n     - On Windows:\\n       ```\\n       env\\\\Scripts\\\\activate\\n       ```\\n\\n2. **Install Required Packages:**\\n   - Install the necessary packages as specified in `requirements.txt`:\\n     ```\\n     pip install -r ../requirements.txt\\n     ```\\n\\n3. **Ensure Docker is Running:**\\n   - It's important that your Kafka broker Docker container is running.\\n   - Validate by running:\\n     ```\\n     docker ps\\n     ```\\n   - If it's not running, navigate to your docker compose yaml file folder and start all instances with:\\n     ```\\n     docker-compose up -d\\n     ```\\n\\n4. **Deactivate the Virtual Environment (when done):**\\n   - Simply run:\\n     ```\\n     deactivate\\n     ```\\n\\nThese steps will help ensure that your Python Kafka setup is correctly configured for running streaming tasks.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'how do i run kafka?'\n",
    "answer = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23e89406-cbb8-4deb-8363-8ae67c447926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To run Kafka, especially when dealing with a Python setup, it is recommended to create a virtual environment and manage dependencies within that environment. Here's how you can do it:\\n\\n1. **Create a Virtual Environment:**\\n   - Run this command to create a virtual environment:\\n     ```\\n     python -m venv env\\n     ```\\n   - Activate the environment:\\n     - On MacOS or Linux:\\n       ```\\n       source env/bin/activate\\n       ```\\n     - On Windows:\\n       ```\\n       env\\\\Scripts\\\\activate\\n       ```\\n\\n2. **Install Required Packages:**\\n   - Install the necessary packages as specified in `requirements.txt`:\\n     ```\\n     pip install -r ../requirements.txt\\n     ```\\n\\n3. **Ensure Docker is Running:**\\n   - It's important that your Kafka broker Docker container is running.\\n   - Validate by running:\\n     ```\\n     docker ps\\n     ```\\n   - If it's not running, navigate to your docker compose yaml file folder and start all instances with:\\n     ```\\n     docker-compose up -d\\n     ```\\n\\n4. **Deactivate the Virtual Environment (when done):**\\n   - Simply run:\\n     ```\\n     deactivate\\n     ```\\n\\nThese steps will help ensure that your Python Kafka setup is correctly configured for running streaming tasks.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c82fd13-9e5b-44ec-89b2-d34e535ad876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff90d28-bb08-4b4f-b7c0-688e932ed55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5d85d3-107c-47d1-9ceb-1e0dcf4c81c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Content-Type, Accept]', Accept version must be either version 8 or 7, but found 9. Accept=application/vnd.elasticsearch+json; compatible-with=9)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mes_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/elasticsearch/_sync/client/utils.py:415\u001b[39m, in \u001b[36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    413\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:2991\u001b[39m, in \u001b[36mElasticsearch.info\u001b[39m\u001b[34m(self, error_trace, filter_path, human, pretty)\u001b[39m\n\u001b[32m   2989\u001b[39m     __query[\u001b[33m\"\u001b[39m\u001b[33mpretty\u001b[39m\u001b[33m\"\u001b[39m] = pretty\n\u001b[32m   2990\u001b[39m __headers = {\u001b[33m\"\u001b[39m\u001b[33maccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m-> \u001b[39m\u001b[32m2991\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2992\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2993\u001b[39m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2998\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[39m, in \u001b[36mBaseClient.perform_request\u001b[39m\u001b[34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mperform_request\u001b[39m(\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    257\u001b[39m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    265\u001b[39m ) -> ApiResponse[Any]:\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._otel.span(\n\u001b[32m    267\u001b[39m         method,\n\u001b[32m    268\u001b[39m         endpoint_id=endpoint_id,\n\u001b[32m    269\u001b[39m         path_parts=path_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    270\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m=\u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m         otel_span.set_elastic_cloud_metadata(response.meta.headers)\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:351\u001b[39m, in \u001b[36mBaseClient._perform_request\u001b[39m\u001b[34m(self, method, path, params, headers, body, otel_span)\u001b[39m\n\u001b[32m    348\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    349\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[32m    352\u001b[39m         message=message, meta=meta, body=resp_body\n\u001b[32m    353\u001b[39m     )\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._verified_elasticsearch:\n\u001b[32m    357\u001b[39m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Content-Type, Accept]', Accept version must be either version 8 or 7, but found 9. Accept=application/vnd.elasticsearch+json; compatible-with=9)"
     ]
    }
   ],
   "source": [
    "es_client.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
